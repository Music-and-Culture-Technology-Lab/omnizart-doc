<!DOCTYPE html>
<html >
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
      <title>Music Transcription</title>
    
      <link rel="stylesheet" href="../_static/pygments.css">
      <link rel="stylesheet" href="../_static/theme.css">
      <link rel="stylesheet" href="../_static/sphinx_press_theme.css">
          <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
          <link rel="stylesheet" href="../_static/css/waveform-list.css" type="text/css" />
      
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>

      <!-- sphinx script_files -->
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>

      
      <script src="../_static/theme-vendors.js"></script>
      <script src="../_static/theme.js" defer></script>
    
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="next" title="Drum Transcription" href="../drum/api.html" />
  <link rel="prev" title="omnizart patch-cnn" href="../patch-cnn/cli.html" /> 
  </head>

  <body>
    <div id="app" class="theme-container" :class="pageClasses"><navbar @toggle-sidebar="toggleSidebar">
  <router-link to="../index.html" class="home-link">
    
      <span class="site-name">omnizart</span>
    
  </router-link>

  <div class="links">
    <navlinks class="can-hide">

  
    <div class="nav-item">
      <a href="../index.html#sound-samples"
         class="nav-link ">
         Contents
      </a>
    </div>
  
    <div class="nav-item">
      <a href="../index.html#sound-samples"
         class="nav-link ">
         Commnad Line Interface
      </a>
    </div>
  
    <div class="nav-item">
      <a href="../index.html#sound-samples"
         class="nav-link  router-link-active">
         API Reference
      </a>
    </div>
  



    </navlinks>
  </div>
</navbar>

      
      <div class="sidebar-mask" @click="toggleSidebar(false)">
      </div>
        <sidebar @toggle-sidebar="toggleSidebar">
          
          <navlinks>
            

  
    <div class="nav-item">
      <a href="../index.html#sound-samples"
         class="nav-link ">
         Contents
      </a>
    </div>
  
    <div class="nav-item">
      <a href="../index.html#sound-samples"
         class="nav-link ">
         Commnad Line Interface
      </a>
    </div>
  
    <div class="nav-item">
      <a href="../index.html#sound-samples"
         class="nav-link  router-link-active">
         API Reference
      </a>
    </div>
  



            
          </navlinks><div id="searchbox" class="searchbox" role="search">
  <div class="caption"><span class="caption-text">Quick search</span>
    <div class="searchformwrapper">
      <form class="search" action="../search.html" method="get">
        <input type="text" name="q" />
        <input type="submit" value="Search" />
        <input type="hidden" name="check_keywords" value="yes" />
        <input type="hidden" name="area" value="default" />
      </form>
    </div>
  </div>
</div><div class="sidebar-links" role="navigation" aria-label="main navigation">
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="../index.html#sound-samples">Contents</a></span>
      </p>
      <ul class="">
        
          <li class="toctree-l1 "><a href="../quick-start.html" class="reference internal ">Quick Start</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../tutorial.html" class="reference internal ">Tutorial</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../demo.html" class="reference internal ">Demonstration</a>

            
          </li>

        
      </ul>
    </div>
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="../index.html#sound-samples">Commnad Line Interface</a></span>
      </p>
      <ul class="">
        
          <li class="toctree-l1 "><a href="cli.html" class="reference internal ">omnizart music</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../drum/cli.html" class="reference internal ">omnizart drum</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../chord/cli.html" class="reference internal ">omnizart chord</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../vocal/cli.html" class="reference internal ">omnizart vocal</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../vocal-contour/cli.html" class="reference internal ">omnizart vocal-contour</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../beat/cli.html" class="reference internal ">omnizart beat</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../patch-cnn/cli.html" class="reference internal ">omnizart patch-cnn</a>

            
          </li>

        
      </ul>
    </div>
  
    <div class="sidebar-group">
      <p class="caption">
        <span class="caption-text"><a href="../index.html#sound-samples">API Reference</a></span>
      </p>
      <ul class="current">
        
          <li class="toctree-l1 current"><a href="#" class="reference internal current">Music Transcription</a>

            
              <ul>
                
                  <li class="toctree-l2"><a href="#feature-storage-format" class="reference internal">Feature Storage Format</a></li>
                
                  <li class="toctree-l2"><a href="#app" class="reference internal">App</a></li>
                
                  <li class="toctree-l2"><a href="#dataset" class="reference internal">Dataset</a></li>
                
                  <li class="toctree-l2"><a href="#module-omnizart.music.inference" class="reference internal">Inference</a></li>
                
                  <li class="toctree-l2"><a href="#module-omnizart.music.losses" class="reference internal">Loss Functions</a></li>
                
                  <li class="toctree-l2"><a href="#module-omnizart.music.labels" class="reference internal">Labels</a></li>
                
                  <li class="toctree-l2"><a href="#module-omnizart.music.prediction" class="reference internal">Prediction</a></li>
                
                  <li class="toctree-l2"><a href="#settings" class="reference internal">Settings</a></li>
                
              </ul>
            
          </li>

        
          <li class="toctree-l1 "><a href="../drum/api.html" class="reference internal ">Drum Transcription</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../chord/api.html" class="reference internal ">Chord Transcription</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../vocal/api.html" class="reference internal ">Vocal Transcription</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../vocal-contour/api.html" class="reference internal ">Vocal-Contour Transcription</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../patch-cnn/api.html" class="reference internal ">Patch-CNN Transcription</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../beat/api.html" class="reference internal ">Beat Transcription</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../feature.html" class="reference internal ">Feature</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../models.html" class="reference internal ">Models</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../training.html" class="reference internal ">Training</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../base.html" class="reference internal ">Base Classes</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../constants.html" class="reference internal ">Constants</a>

            
          </li>

        
          <li class="toctree-l1 "><a href="../utils.html" class="reference internal ">Utilities</a>

            
          </li>

        
      </ul>
    </div>
  
</div>
        </sidebar>

      <page>
          <div class="body-header" role="navigation" aria-label="navigation">
  
  <ul class="breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
    
    <li>Music Transcription</li>
  </ul>
  

  <ul class="page-nav">
  <li class="prev">
    <a href="../patch-cnn/cli.html"
       title="previous chapter">← omnizart patch-cnn</a>
  </li>
  <li class="next">
    <a href="../drum/api.html"
       title="next chapter">Drum Transcription →</a>
  </li>
</ul>
  
</div>
<hr>
          <div class="content" role="main">
            
  <div class="section" id="module-omnizart.music">
<span id="music-transcription"></span><h1>Music Transcription<a class="headerlink" href="#module-omnizart.music" title="Permalink to this headline">¶</a></h1>
<p>Music transcription module.</p>
<p>This module provides utilities for transcribing pitch and instruments in the audio.
This module is also an improved version of the original repository
<a class="reference external" href="https://github.com/BreezeWhite/Music-Transcription-with-Semantic-Segmentation">BreezeWhite/Music-Transcription-with-Semantic-Segmentation</a>,
with a cleaner architecture and consistent coding style, also provides command line interface
for easy usage.</p>
<div class="section" id="feature-storage-format">
<h2>Feature Storage Format<a class="headerlink" href="#feature-storage-format" title="Permalink to this headline">¶</a></h2>
<p>Processed feature will be stored in <code class="docutils literal notranslate"><span class="pre">.hdf</span></code> and <code class="docutils literal notranslate"><span class="pre">.pickle</span></code> file format. The former format
is used to store the feature representation, and the later is used for customized label
representation. Each piece will have both two different files.</p>
<p>Columns in <code class="docutils literal notranslate"><span class="pre">.hdf</span></code> feature file:</p>
<ul class="simple">
<li><p><strong>feature</strong></p></li>
</ul>
<div class="section" id="references">
<h3>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h3>
<p>Technical details can be found in the publications <a class="reference internal" href="#r96142b21d69a-1" id="id1">[1]</a>, <a class="reference internal" href="#r96142b21d69a-2" id="id2">[2]</a>, and <a class="reference internal" href="#r96142b21d69a-3" id="id3">[3]</a>.</p>
<dl class="citation">
<dt class="label" id="r96142b21d69a-1"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Yu-Te Wu, Berlin Chen, and Li Su, “Multi-Instrument Automatic Music Transcription With Self-Attention-Based
Instance Segmentation.” in IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2020.</p>
</dd>
<dt class="label" id="r96142b21d69a-2"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Yu-Te Wu, Berlin Chen, and Li Su. “Polyphonic Music Transcription with Semantic Segmentation.”
IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019.</p>
</dd>
<dt class="label" id="r96142b21d69a-3"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Yu-Te Wu, Berlin Chen, and Li Su. “Automatic Music Yranscription Leveraging Generalized Cepstral Features and
Deep Learning.” IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018.</p>
</dd>
</dl>
</div>
</div>
<div class="section" id="app">
<h2>App<a class="headerlink" href="#app" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="omnizart.music.app.MusicTranscription">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">omnizart.music.app.</span></code><code class="sig-name descname"><span class="pre">MusicTranscription</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">conf_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.app.MusicTranscription" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../base.html#omnizart.base.BaseTranscription" title="omnizart.base.BaseTranscription"><code class="xref py py-class docutils literal notranslate"><span class="pre">omnizart.base.BaseTranscription</span></code></a></p>
<p>Application class for music transcription.</p>
<p>Inherited from the BaseTranscription class to make sure everything
needed got override.</p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#omnizart.music.app.MusicTranscription.generate_feature" title="omnizart.music.app.MusicTranscription.generate_feature"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_feature</span></code></a>(dataset_path[, …])</p></td>
<td><p>Extract the feature from the given dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#omnizart.music.app.MusicTranscription.train" title="omnizart.music.app.MusicTranscription.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>(feature_folder[, model_name, …])</p></td>
<td><p>Model training.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#omnizart.music.app.MusicTranscription.transcribe" title="omnizart.music.app.MusicTranscription.transcribe"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transcribe</span></code></a>(input_audio[, model_path, output])</p></td>
<td><p>Transcribe notes and instruments of the given audio.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="omnizart.music.app.MusicTranscription.generate_feature">
<code class="sig-name descname"><span class="pre">generate_feature</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">music_settings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_threads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.app.MusicTranscription.generate_feature" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract the feature from the given dataset.</p>
<p>To train the model, the first step is to pre-process the data into feature
representations. After downloading the dataset, use this function to generate
the feature by giving the path of the stored dataset.</p>
<p>To specify the output path, modify the attribute
<code class="docutils literal notranslate"><span class="pre">music_settings.dataset.feature_save_path</span></code>.
It defaults to the folder under where the dataset stored, generating
two folders: <code class="docutils literal notranslate"><span class="pre">train_feature</span></code> and <code class="docutils literal notranslate"><span class="pre">test_feature</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>dataset_path: Path</strong></dt><dd><p>Path to the downloaded dataset.</p>
</dd>
<dt><strong>music_settings: MusicSettings</strong></dt><dd><p>The configuration instance that holds all relative settings for
the life-cycle of building a model.</p>
</dd>
<dt><strong>num_threads:</strong></dt><dd><p>Number of threads for parallel extraction the feature.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="../constants.html#module-omnizart.constants.datasets" title="omnizart.constants.datasets"><code class="xref py py-obj docutils literal notranslate"><span class="pre">omnizart.constants.datasets</span></code></a></dt><dd><p>The supported datasets and the corresponding training/testing splits.</p>
</dd>
</dl>
</div>
</dd></dl>

<dl class="py method">
<dt id="omnizart.music.app.MusicTranscription.train">
<code class="sig-name descname"><span class="pre">train</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature_folder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_model_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">music_settings</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.app.MusicTranscription.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Model training.</p>
<p>Train the model from scratch or continue training given a model checkpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature_folder: Path</strong></dt><dd><p>Path to the generated feature.</p>
</dd>
<dt><strong>model_name: str</strong></dt><dd><p>The name of the trained model. If not given, will default to the
current timestamp.</p>
</dd>
<dt><strong>input_model_path: Path</strong></dt><dd><p>Specify the path to the model checkpoint in order to fine-tune
the model.</p>
</dd>
<dt><strong>music_settings: MusicSettings</strong></dt><dd><p>The configuration that holds all relative settings for
the life-cycle of model building.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="omnizart.music.app.MusicTranscription.transcribe">
<code class="sig-name descname"><span class="pre">transcribe</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_audio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.app.MusicTranscription.transcribe" title="Permalink to this definition">¶</a></dt>
<dd><p>Transcribe notes and instruments of the given audio.</p>
<p>This function transcribes notes (onset, duration) of each instruments in the audio.
The results will be written out as a MIDI file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>input_audio: Path</strong></dt><dd><p>Path to the wav audio file.</p>
</dd>
<dt><strong>model_path: Path</strong></dt><dd><p>Path to the trained model or the transcription mode. If given a path, should be
the folder that contains <cite>arch.yaml</cite>, <cite>weights.h5</cite>, and <cite>configuration.yaml</cite>.</p>
</dd>
<dt><strong>output: Path (optional)</strong></dt><dd><p>Path for writing out the transcribed MIDI file. Default to current path.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>midi: pretty_midi.PrettyMIDI</dt><dd><p>The transcribed notes of different instruments.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><code class="xref py py-obj docutils literal notranslate"><span class="pre">omnizart.cli.music.transcribe</span></code></dt><dd><p>The coressponding command line entry.</p>
</dd>
</dl>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dataset">
<h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="omnizart.music.app.MusicDatasetLoader">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">omnizart.music.app.</span></code><code class="sig-name descname"><span class="pre">MusicDatasetLoader</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_conversion_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_folder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[1,</span> <span class="pre">3]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">352</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.app.MusicDatasetLoader" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="../base.html#omnizart.base.BaseDatasetLoader" title="omnizart.base.BaseDatasetLoader"><code class="xref py py-class docutils literal notranslate"><span class="pre">omnizart.base.BaseDatasetLoader</span></code></a></p>
<p>Data loader for training the mdoel of <code class="docutils literal notranslate"><span class="pre">music</span></code>.</p>
<p>Load feature and label for training. Also converts the custom format of
label into piano roll representation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label_conversion_func: callable</strong></dt><dd><p>The function that will be used for converting the customized label format
into numpy array.</p>
</dd>
<dt><strong>feature_folder: Path</strong></dt><dd><p>Path to the extracted feature files, including <cite>*.hdf</cite> and <cite>*.pickle</cite> pairs,
which refers to feature and label files, respectively.</p>
</dd>
<dt><strong>feature_files: list[Path]</strong></dt><dd><p>List of path of <cite>*.hdf</cite> feature files. Corresponding label files should also
under the same folder.</p>
</dd>
<dt><strong>num_samples: int</strong></dt><dd><p>Total number of samples to yield.</p>
</dd>
<dt><strong>timesteps: int</strong></dt><dd><p>Time length of the feature.</p>
</dd>
<dt><strong>channels: list[int]</strong></dt><dd><p>Channels to be used for training. Allowed values are [1, 2, 3].</p>
</dd>
<dt><strong>feature_num: int</strong></dt><dd><p>Target size of feature dimension.
Zero padding is done to resolve mismatched input and target size.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><dl class="simple">
<dt>feature:</dt><dd><p>Input features for model training.</p>
</dd>
<dt>label:</dt><dd><p>Corresponding labels.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-omnizart.music.inference">
<span id="inference"></span><h2>Inference<a class="headerlink" href="#module-omnizart.music.inference" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="omnizart.music.inference.down_sample">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">down_sample</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">occur_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.down_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Down sample multi-channel predictions along the feature dimension.</p>
<p>Down sample the feature size from 354 to 88 for infering the notes from a multi-channel prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>pred: 3D numpy array</strong></dt><dd><p>Thresholded prediction with multiple channels. Dimension: [timesteps x pitch x instruments]</p>
</dd>
<dt><strong>occur_num: int</strong></dt><dd><p>Minimum occurance of each pitch for determining true activation of the pitch.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>d_sample: 3D numpy array</dt><dd><p>Down-sampled prediction. Dimension: [timesteps x 88 x instruments]</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.find_min_max_stren">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">find_min_max_stren</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">notes</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.find_min_max_stren" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for detemine the note velocity accroding to prediction value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>notes: list[dict]</strong></dt><dd><p>Data structure returned by function <cite>infer_piece</cite>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.find_occur">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">find_occur</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pitch</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_unit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_duration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.03</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.find_occur" title="Permalink to this definition">¶</a></dt>
<dd><p>Find the onset and offset of a thresholded prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>pitch: 1D numpy array</strong></dt><dd><p>Time series of predicted pitch activations.</p>
</dd>
<dt><strong>t_unit: float</strong></dt><dd><p>Time unit of each entry.</p>
</dd>
<dt><strong>min_duration: float</strong></dt><dd><p>Minimum interval of each note in seconds.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.infer_piece">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">infer_piece</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">piece</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shortest_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">offset_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.12</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_unit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.infer_piece" title="Permalink to this definition">¶</a></dt>
<dd><p>Dim: time x 88 x 4 (off, dura, onset, offset)</p>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.interpolation">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">interpolation</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ori_t_unit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tar_t_unit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.interpolation" title="Permalink to this definition">¶</a></dt>
<dd><p>Interpolate between each frame to increase the time resolution.</p>
<p>The default setting of feature extraction has time resolution of 0.02 seconds for each frame.
To fit the conventional evaluation settings, which has time resolution of 0.01 seconds, we additionally
apply the interpolation function to increase time resolution. Here we use <cite>Cubic Spline</cite> for the
estimation.</p>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.multi_inst_note_inference">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">multi_inst_note_inference</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'note-stream'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onset_th</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dura_th</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frm_th</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inst_th</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_unit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_program_mapping</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0,</span> <span class="pre">6,</span> <span class="pre">40,</span> <span class="pre">41,</span> <span class="pre">42,</span> <span class="pre">43,</span> <span class="pre">60,</span> <span class="pre">68,</span> <span class="pre">70,</span> <span class="pre">71,</span> <span class="pre">73]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.multi_inst_note_inference" title="Permalink to this definition">¶</a></dt>
<dd><p>Function for infering raw multi-instrument predictions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>mode: {‘note-stream’, ‘note’, ‘frame-stream’, ‘frame’}</strong></dt><dd><p>Inference mode.
Difference between ‘note’ and ‘frame’ is that the former consists of two note attributes, which are ‘onset’ and
‘duration’, and the later only contains ‘duration’, which in most of the cases leads to worse listening
experience.
With postfix ‘stream’ refers to transcribe instrument at the same time, meaning classifying each notes into
instrument classes, or says different tracks.</p>
</dd>
<dt><strong>onset_th: float</strong></dt><dd><p>Threshold of onset channel. Type of list or float</p>
</dd>
<dt><strong>dura_th: float</strong></dt><dd><p>Threshold of duration channel. Type of list or float</p>
</dd>
<dt><strong>inst_th: float</strong></dt><dd><p>Threshold of deciding a instrument is present or not according to Std. of prediction.</p>
</dd>
<dt><strong>normalize: bool</strong></dt><dd><p>Whether to normalize the predictions. For more details, please refer to our
<a class="reference external" href="https://bit.ly/2QhdWX5">paper</a></p>
</dd>
<dt><strong>t_unit: float</strong></dt><dd><p>Time unit for each frame. Should not be modified unless you have different settings during the feature
extraction</p>
</dd>
<dt><strong>channel_program_mapping: list[int]</strong></dt><dd><p>Mapping prediction channels to MIDI program numbers.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>out_midi</dt><dd><p>A pretty_midi.PrettyMIDI object.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">References</p>
<p>Publications can be found <a class="reference external" href="https://bit.ly/2QhdWX5">here</a>.</p>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.norm_onset_dura">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">norm_onset_dura</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onset_th</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dura_th</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.norm_onset_dura" title="Permalink to this definition">¶</a></dt>
<dd><p>Normalizes prediction values of onset and duration channel.</p>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.norm_split_onset_dura">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">norm_split_onset_dura</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onset_th</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lower_onset_th</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">split_bound</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dura_th</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpolate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.norm_split_onset_dura" title="Permalink to this definition">¶</a></dt>
<dd><p>An advanced version of function for normalizing onset and duration channel.</p>
<p>From the extensive experiments, we observe that the average prediction value for high and low frequency are
different. Lower pitches tend to have smaller values, while higher pitches having larger. To acheive better
transcription results, the most straight-forward solution is to assign different thresholds for low and
high frequency part. And this is what this function provides for the purpose.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>pred</strong></dt><dd><p>The predictions.</p>
</dd>
<dt><strong>onset_th: float</strong></dt><dd><p>Threshold for high frequency part.</p>
</dd>
<dt><strong>lower_onset_th: float</strong></dt><dd><p>Threshold for low frequency part.</p>
</dd>
<dt><strong>split_bound: int</strong></dt><dd><p>The split point of low and high frequency part. Value should be within 0~87.</p>
</dd>
<dt><strong>interpolate: bool</strong></dt><dd><p>Whether to apply interpolation between each frame to increase time resolution.</p>
</dd>
<dt><strong>normalize: bool</strong></dt><dd><p>Whether to normalize the prediction values.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>pred</dt><dd><p>Thresholded prediction, having value either 0 or 1.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.roll_down_sample">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">roll_down_sample</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">occur_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">88</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.roll_down_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Down sample feature size for a single pitch.</p>
<p>Down sample the feature size from 354 to 88 for infering the notes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>data: 2D numpy array</strong></dt><dd><p>The thresholded 2D prediction..</p>
</dd>
<dt><strong>occur_num: int</strong></dt><dd><p>For each pitch, the original prediction expands 4 bins wide. This value determines how many positive bins
should there be to say there is a real activation after down sampling.</p>
</dd>
<dt><strong>base</strong></dt><dd><p>Should be constant as there are 88 pitches on the piano.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>return_v: 2D numpy array</dt><dd><p>Down sampled prediction.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The parameter <cite>data</cite> should be thresholded!</p>
</div>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.threshold_type_converter">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">threshold_type_converter</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">length</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.threshold_type_converter" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert scalar value to a list with the same value.</p>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.inference.to_midi">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.inference.</span></code><code class="sig-name descname"><span class="pre">to_midi</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">notes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_unit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.inference.to_midi" title="Permalink to this definition">¶</a></dt>
<dd><p>Translate the intermediate data into final output MIDI file.</p>
</dd></dl>

</div>
<div class="section" id="module-omnizart.music.losses">
<span id="loss-functions"></span><h2>Loss Functions<a class="headerlink" href="#module-omnizart.music.losses" title="Permalink to this headline">¶</a></h2>
<p>Loss functions for Music module.</p>
<dl class="py function">
<dt id="omnizart.music.losses.focal_loss">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.losses.</span></code><code class="sig-name descname"><span class="pre">focal_loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">target_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prediction_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.losses.focal_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute focal loss for predictions.</p>
<p>Multi-labels Focal loss formula:</p>
<div class="math notranslate nohighlight">
\[FL = -\alpha * (z-p)^\gamma * \log{(p)} -(1-\alpha) * p^\gamma * \log{(1-p)}\]</div>
<p>Which <span class="math notranslate nohighlight">\(\alpha\)</span> = 0.25, <span class="math notranslate nohighlight">\(\gamma\)</span> = 2, p = sigmoid(x), z = target_tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>prediction_tensor</strong></dt><dd><p>A float tensor of shape [batch_size, num_anchors, num_classes] representing the predicted logits for each
class.</p>
</dd>
<dt><strong>target_tensor:</strong></dt><dd><p>A float tensor of shape [batch_size, num_anchors, num_classes] representing one-hot encoded classification
targets.</p>
</dd>
<dt><strong>weights</strong></dt><dd><p>A float tensor of shape [batch_size, num_anchors].</p>
</dd>
<dt><strong>alpha</strong></dt><dd><p>A scalar tensor for focal loss alpha hyper-parameter.</p>
</dd>
<dt><strong>gamma</strong></dt><dd><p>A scalar tensor for focal loss gamma hyper-parameter.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>loss</dt><dd><p>A scalar tensor representing the value of the loss function</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.losses.smooth_loss">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.losses.</span></code><code class="sig-name descname"><span class="pre">smooth_loss</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.15</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">total_chs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">22</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.losses.smooth_loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Function to compute loss after applying <strong>label-smoothing</strong>.</p>
</dd></dl>

</div>
<div class="section" id="module-omnizart.music.labels">
<span id="labels"></span><h2>Labels<a class="headerlink" href="#module-omnizart.music.labels" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="omnizart.music.labels.BaseLabelExtraction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">omnizart.music.labels.</span></code><code class="sig-name descname"><span class="pre">BaseLabelExtraction</span></code><a class="headerlink" href="#omnizart.music.labels.BaseLabelExtraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for extract label informations.</p>
<p>Provides basic functions to process native label format into the format
required by <code class="docutils literal notranslate"><span class="pre">music</span></code> module. All sub-classes should parse the original
label information into <code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code> class.</p>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#omnizart.music.labels.label_conversion" title="omnizart.music.labels.label_conversion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">omnizart.music.labels.label_conversion</span></code></a></dt><dd></dd>
</dl>
</div>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#omnizart.music.labels.BaseLabelExtraction.extract_label" title="omnizart.music.labels.BaseLabelExtraction.extract_label"><code class="xref py py-obj docutils literal notranslate"><span class="pre">extract_label</span></code></a>(label_path, t_unit[, …])</p></td>
<td><p>Extract labels into customized storage format.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#omnizart.music.labels.BaseLabelExtraction.load_label" title="omnizart.music.labels.BaseLabelExtraction.load_label"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_label</span></code></a>(label_path)</p></td>
<td><p>Load the label file and parse information into <code class="docutils literal notranslate"><span class="pre">Label</span></code> class.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#omnizart.music.labels.BaseLabelExtraction.name_transform" title="omnizart.music.labels.BaseLabelExtraction.name_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name_transform</span></code></a>(name)</p></td>
<td><p>Maps the filename of label to the same name of the corresponding wav file.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#omnizart.music.labels.BaseLabelExtraction.process" title="omnizart.music.labels.BaseLabelExtraction.process"><code class="xref py py-obj docutils literal notranslate"><span class="pre">process</span></code></a>(label_list, out_path[, t_unit, …])</p></td>
<td><p>Process the given list of label files and output to the target folder.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="omnizart.music.labels.BaseLabelExtraction.extract_label">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">extract_label</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_unit</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onset_len_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.BaseLabelExtraction.extract_label" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract labels into customized storage format.</p>
<p>Process the given path of label into list of <code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code> instances,
then further convert them into deliberately customized storage format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label_path: Path</strong></dt><dd><p>Path to the label file.</p>
</dd>
<dt><strong>t_unit: float</strong></dt><dd><p>Time unit of each step in seconds. Should be consistent with the time unit of
each frame of the extracted feature.</p>
</dd>
<dt><strong>onset_len_sec: float</strong></dt><dd><p>Length of the first few frames with probability one. The later onset
probabilities will be in a ‘fade-out’ manner until the note offset.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.BaseLabelExtraction.load_label">
<em class="property"><span class="pre">abstract</span> <span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">load_label</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.BaseLabelExtraction.load_label" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the label file and parse information into <code class="docutils literal notranslate"><span class="pre">Label</span></code> class.</p>
<p>Sub-classes should override this function to process their own label
format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label_path: Path</strong></dt><dd><p>Path to the label file.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>labels: list[Label]</dt><dd><p>List of <code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code> instances.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.BaseLabelExtraction.name_transform">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">name_transform</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.BaseLabelExtraction.name_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Maps the filename of label to the same name of the corresponding wav file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>name: str</strong></dt><dd><p>Name of the label file, without parent directory prefix and file extension.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>trans_name: str</dt><dd><p>The name same as the coressponding wav (or says feature) file.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.BaseLabelExtraction.process">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">process</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_unit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.02</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onset_len_sec</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.BaseLabelExtraction.process" title="Permalink to this definition">¶</a></dt>
<dd><p>Process the given list of label files and output to the target folder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label_list: list[Path]</strong></dt><dd><p>List of label paths.</p>
</dd>
<dt><strong>out_path: Path</strong></dt><dd><p>Path for saving the extracted label files.</p>
</dd>
<dt><strong>t_unit: float</strong></dt><dd><p>Time unit of each step in seconds. Should be consistent with the time unit of
each frame of the extracted feature.</p>
</dd>
<dt><strong>onset_len_sec: float</strong></dt><dd><p>Length of the first few frames with probability one. The later onset
probabilities will be in a ‘fade-out’ manner until the note offset.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="omnizart.music.labels.LabelType">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">omnizart.music.labels.</span></code><code class="sig-name descname"><span class="pre">LabelType</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.LabelType" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines different types of <cite>music</cite> label for training.</p>
<p>Defines functions that converts the customized label format into numpy
array. With the customized format, it is more flexible to transform
labels into different different numpy formats according to the usage
scenario, and also saves a lot of storage space by using the customized
format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>mode: [‘note’, ‘note-stream’, ‘pop-note-stream’, ‘frame’, ‘frame-stream’]</strong></dt><dd><p>Mode of label conversion.</p>
<ul class="simple">
<li><p>note: outputs onset and duration channel</p></li>
<li><p>note-stream: outputs onset and duration channel of instruments (for MusicNet)</p></li>
<li><p>pop-note-stream: similar to <code class="docutils literal notranslate"><span class="pre">note-stream</span></code> mode, but is for <code class="docutils literal notranslate"><span class="pre">Pop</span></code> dataset</p></li>
<li><p>frame: same as <code class="docutils literal notranslate"><span class="pre">note</span></code> mode. To truely output duration channel only, use         <cite>true-frame</cite> mode.</p></li>
<li><p>frame-stream: same as <code class="docutils literal notranslate"><span class="pre">note-stream</span></code>. To truely output duration channel only         for each instrument, use <code class="docutils literal notranslate"><span class="pre">true-frame-stream</span></code> mode.</p></li>
</ul>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 70%" />
<col style="width: 30%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><strong>get_available_modes</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_conversion_func</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_frame</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>get_frame_onset</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>get_out_classes</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>multi_inst_frm</strong></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><strong>multi_inst_note</strong></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><strong>multi_pop_note</strong></p></td>
<td></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="omnizart.music.labels.LabelType.get_available_modes">
<code class="sig-name descname"><span class="pre">get_available_modes</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.LabelType.get_available_modes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.LabelType.get_conversion_func">
<code class="sig-name descname"><span class="pre">get_conversion_func</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.LabelType.get_conversion_func" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.LabelType.get_frame">
<code class="sig-name descname"><span class="pre">get_frame</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.LabelType.get_frame" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.LabelType.get_frame_onset">
<code class="sig-name descname"><span class="pre">get_frame_onset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.LabelType.get_frame_onset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.LabelType.get_out_classes">
<code class="sig-name descname"><span class="pre">get_out_classes</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.LabelType.get_out_classes" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.LabelType.multi_inst_frm">
<code class="sig-name descname"><span class="pre">multi_inst_frm</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.LabelType.multi_inst_frm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.LabelType.multi_inst_note">
<code class="sig-name descname"><span class="pre">multi_inst_note</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.LabelType.multi_inst_note" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="omnizart.music.labels.LabelType.multi_pop_note">
<code class="sig-name descname"><span class="pre">multi_pop_note</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.LabelType.multi_pop_note" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt id="omnizart.music.labels.MaestroLabelExtraction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">omnizart.music.labels.</span></code><code class="sig-name descname"><span class="pre">MaestroLabelExtraction</span></code><a class="headerlink" href="#omnizart.music.labels.MaestroLabelExtraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Label extraction class for Maestro dataset</p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#omnizart.music.labels.MaestroLabelExtraction.load_label" title="omnizart.music.labels.MaestroLabelExtraction.load_label"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_label</span></code></a>(label_path)</p></td>
<td><p>Load the label file and parse information into <code class="docutils literal notranslate"><span class="pre">Label</span></code> class.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="omnizart.music.labels.MaestroLabelExtraction.load_label">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">load_label</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.MaestroLabelExtraction.load_label" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the label file and parse information into <code class="docutils literal notranslate"><span class="pre">Label</span></code> class.</p>
<p>Sub-classes should override this function to process their own label
format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label_path: Path</strong></dt><dd><p>Path to the label file.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>labels: list[Label]</dt><dd><p>List of <code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code> instances.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="omnizart.music.labels.MapsLabelExtraction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">omnizart.music.labels.</span></code><code class="sig-name descname"><span class="pre">MapsLabelExtraction</span></code><a class="headerlink" href="#omnizart.music.labels.MapsLabelExtraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Label extraction class for Maps dataset</p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#omnizart.music.labels.MapsLabelExtraction.load_label" title="omnizart.music.labels.MapsLabelExtraction.load_label"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_label</span></code></a>(label_path)</p></td>
<td><p>Load the label file and parse information into <code class="docutils literal notranslate"><span class="pre">Label</span></code> class.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="omnizart.music.labels.MapsLabelExtraction.load_label">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">load_label</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.MapsLabelExtraction.load_label" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the label file and parse information into <code class="docutils literal notranslate"><span class="pre">Label</span></code> class.</p>
<p>Sub-classes should override this function to process their own label
format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label_path: Path</strong></dt><dd><p>Path to the label file.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>labels: list[Label]</dt><dd><p>List of <code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code> instances.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="omnizart.music.labels.MusicNetLabelExtraction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">omnizart.music.labels.</span></code><code class="sig-name descname"><span class="pre">MusicNetLabelExtraction</span></code><a class="headerlink" href="#omnizart.music.labels.MusicNetLabelExtraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Label extraction class for MusicNet dataset</p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#omnizart.music.labels.MusicNetLabelExtraction.load_label" title="omnizart.music.labels.MusicNetLabelExtraction.load_label"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_label</span></code></a>(label_path)</p></td>
<td><p>Load the label file and parse information into <code class="docutils literal notranslate"><span class="pre">Label</span></code> class.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="omnizart.music.labels.MusicNetLabelExtraction.load_label">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">load_label</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label_path</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.MusicNetLabelExtraction.load_label" title="Permalink to this definition">¶</a></dt>
<dd><p>Load the label file and parse information into <code class="docutils literal notranslate"><span class="pre">Label</span></code> class.</p>
<p>Sub-classes should override this function to process their own label
format.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label_path: Path</strong></dt><dd><p>Path to the label file.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>labels: list[Label]</dt><dd><p>List of <code class="xref py py-class docutils literal notranslate"><span class="pre">Label</span></code> instances.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="omnizart.music.labels.PopLabelExtraction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">omnizart.music.labels.</span></code><code class="sig-name descname"><span class="pre">PopLabelExtraction</span></code><a class="headerlink" href="#omnizart.music.labels.PopLabelExtraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Label extraction class for Pop Rhythm dataset</p>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#omnizart.music.labels.PopLabelExtraction.name_transform" title="omnizart.music.labels.PopLabelExtraction.name_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">name_transform</span></code></a>(name)</p></td>
<td><p>Maps the filename of label to the same name of the corresponding wav file.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="omnizart.music.labels.PopLabelExtraction.name_transform">
<em class="property"><span class="pre">classmethod</span> </em><code class="sig-name descname"><span class="pre">name_transform</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.PopLabelExtraction.name_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Maps the filename of label to the same name of the corresponding wav file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>name: str</strong></dt><dd><p>Name of the label file, without parent directory prefix and file extension.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>trans_name: str</dt><dd><p>The name same as the coressponding wav (or says feature) file.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="omnizart.music.labels.SuLabelExtraction">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">omnizart.music.labels.</span></code><code class="sig-name descname"><span class="pre">SuLabelExtraction</span></code><a class="headerlink" href="#omnizart.music.labels.SuLabelExtraction" title="Permalink to this definition">¶</a></dt>
<dd><p>Label extraction class for Extended-Su dataset</p>
<p>Uses the same process as Maestro dataset</p>
</dd></dl>

<dl class="py function">
<dt id="omnizart.music.labels.label_conversion">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.labels.</span></code><code class="sig-name descname"><span class="pre">label_conversion</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">label</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ori_feature_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">352</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">352</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">88</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mpe</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">onsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">channel_mapping</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.labels.label_conversion" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts the customized label format into numpy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>label: object</strong></dt><dd><p>List of dict that is in customized label format.</p>
</dd>
<dt><strong>ori_feature_size: int</strong></dt><dd><p>Size of the original feature dimension.</p>
</dd>
<dt><strong>feature_num: int</strong></dt><dd><p>Size of the target output feature dimension.</p>
</dd>
<dt><strong>base: int</strong></dt><dd><p>Number of total available pitches.</p>
</dd>
<dt><strong>mpe: bool</strong></dt><dd><p>Whether to merge all channels into a single one, discarding information
about instruments.</p>
</dd>
<dt><strong>onsets: bool</strong></dt><dd><p>Fill in onset probabilities if set to true, or fill one to all activations.</p>
</dd>
<dt><strong>channel_mapping: dict</strong></dt><dd><p>Maps the instrument program number to the specified channel index, used
to indicate which channel should represent what instruments.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<dl class="simple">
<dt><a class="reference internal" href="#omnizart.music.labels.BaseLabelExtraction.extract_label" title="omnizart.music.labels.BaseLabelExtraction.extract_label"><code class="xref py py-obj docutils literal notranslate"><span class="pre">omnizart.music.labels.BaseLabelExtraction.extract_label</span></code></a></dt><dd><p>Function that generates the customized label format.</p>
</dd>
</dl>
</div>
</dd></dl>

</div>
<div class="section" id="module-omnizart.music.prediction">
<span id="prediction"></span><h2>Prediction<a class="headerlink" href="#module-omnizart.music.prediction" title="Permalink to this headline">¶</a></h2>
<p>Utility functions for Music module</p>
<dl class="py function">
<dt id="omnizart.music.prediction.predict">
<code class="sig-prename descclassname"><span class="pre">omnizart.music.prediction.</span></code><code class="sig-name descname"><span class="pre">predict</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">feature</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">timesteps</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">128</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">384</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#omnizart.music.prediction.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Make predictions on the feature.</p>
<p>Generate predictions by using the loaded model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature: numpy.ndarray</strong></dt><dd><p>Extracted feature of the audio.
Dimension:  timesteps x feature_size x channels</p>
</dd>
<dt><strong>model: keras.Model</strong></dt><dd><p>The loaded model instance</p>
</dd>
<dt><strong>feature_num: int</strong></dt><dd><p>Padding along the feature dimension to the size <cite>feature_num</cite></p>
</dd>
<dt><strong>batch_size: int</strong></dt><dd><p>Batch size for each step of prediction. The size is depending on the available GPU memory.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt>pred: numpy.ndarray</dt><dd><p>The predicted results. The values are ranging from 0~1.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="settings">
<h2>Settings<a class="headerlink" href="#settings" title="Permalink to this headline">¶</a></h2>
<p>Below are the default settings for building the music model. It will be loaded
by the class <code class="xref py py-class docutils literal notranslate"><span class="pre">omnizart.setting_loaders.MusicSettings</span></code>. The name of the
attributes will be converted to snake-case (e.g. HopSize -&gt; hop_size). There
is also a path transformation process when applying the settings into the
<code class="docutils literal notranslate"><span class="pre">MusicSettings</span></code> instance. For example, if you want to access the attribute
<code class="docutils literal notranslate"><span class="pre">BatchSize</span></code> defined in the yaml path <em>General/Training/Settings/BatchSize</em>,
the coressponding attribute will be <em>MusicSettings.training.batch_size</em>.
The level of <em>/Settings</em> is removed among all fields.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># Self-documented configurable settings, with description, type hint, and available</span>
<span class="c1"># options. All the parameters can be overriden by another specified configuration file </span>
<span class="c1"># with selected parameters.</span>


<span class="nt">General</span><span class="p">:</span>
    <span class="nt">TranscriptionMode</span><span class="p">:</span>
        <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Mode of transcription by executing the `omnizart music transcribe` command.</span>
        <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span> 
        <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Piano</span>
    <span class="nt">CheckpointPath</span><span class="p">:</span>
        <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Path to the pre-trained models.</span>
        <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Map</span>
        <span class="nt">SubType</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">String</span><span class="p p-Indicator">,</span> <span class="nv">String</span><span class="p p-Indicator">]</span>
        <span class="nt">Value</span><span class="p">:</span>
            <span class="nt">Piano</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">checkpoints/music/music_piano</span>
            <span class="nt">Pop</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">checkpoints/music/music_pop</span>
            <span class="nt">Stream</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">checkpoints/music/music_note_stream</span>
    <span class="nt">Feature</span><span class="p">:</span>
        <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Default settings of feature extraction</span>
        <span class="nt">Settings</span><span class="p">:</span>
            <span class="nt">HopSize</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Hop size in seconds with respect to sampling rate.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.02</span>
            <span class="nt">SamplingRate</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Adjust input sampling rate to this value.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">44100</span>
            <span class="nt">WindowSize</span><span class="p">:</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">7939</span>
            <span class="nt">FrequencyResolution</span><span class="p">:</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2.0</span>
            <span class="nt">FrequencyCenter</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Lowest frequency to extract.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">27.5</span>
            <span class="nt">TimeCenter</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Highest frequency to extract (1/time_center).</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.00022287</span>
            <span class="nt">Gamma</span><span class="p">:</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">List</span>
                <span class="nt">SubType</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.24</span><span class="p p-Indicator">,</span> <span class="nv">0.6</span><span class="p p-Indicator">,</span> <span class="nv">1.0</span><span class="p p-Indicator">]</span>
            <span class="nt">BinsPerOctave</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Number of bins for each octave.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">48</span>
            <span class="nt">HarmonicNumber</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Number of harmonic bins of HCFP feature.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">6</span>
            <span class="nt">Harmonic</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Whether to use harmonic version of the input feature for training.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Bool</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span>
    <span class="nt">Dataset</span><span class="p">:</span>
        <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Settings of datasets.</span>
        <span class="nt">Settings</span><span class="p">:</span>
            <span class="nt">SavePath</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Path for storing the downloaded datasets.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">./</span>
            <span class="nt">FeatureType</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Type of feature to extract.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">CFP</span>
                <span class="nt">Choices</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;CFP&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;HCFP&quot;</span><span class="p p-Indicator">]</span>
            <span class="nt">FeatureSavePath</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Path for storing the extracted feature. Default to the path under the dataset folder.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">+</span>
    <span class="nt">Model</span><span class="p">:</span>
        <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Default settings of training / testing the model.</span>
        <span class="nt">Settings</span><span class="p">:</span>
            <span class="nt">SavePrefix</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Prefix of the trained model&#39;s name to be saved.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">music</span>
            <span class="nt">SavePath</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Path to save the trained model.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">./checkpoints/music</span>
            <span class="nt">ModelType</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Default model type to be used for training</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">attn</span>
                <span class="nt">Choices</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;aspp&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;attn&quot;</span><span class="p p-Indicator">]</span>
    <span class="nt">Inference</span><span class="p">:</span>
        <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Default settings when infering notes.</span>
        <span class="nt">Settings</span><span class="p">:</span>
            <span class="nt">MinLength</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Minimum length of a note in seconds.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.05</span>
            <span class="nt">InstTh</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Threshold for filtering instruments.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1.1</span>
            <span class="nt">OnsetTh</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Threshold of predicted onset channel.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">6.0</span>
            <span class="nt">DuraTh</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Threshold of predicted duration channel.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.5</span>
            <span class="nt">FrameTh</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Threshold of frame-level predictions.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Float</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.5</span>
    <span class="nt">Training</span><span class="p">:</span>
        <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Parameters for training</span>
        <span class="nt">Settings</span><span class="p">:</span>
            <span class="nt">Epoch</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Maximum number of epochs for training.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">20</span>
            <span class="nt">Steps</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Number of training steps for each epoch.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3000</span>
            <span class="nt">ValSteps</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Number of validation steps after each training epoch.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">500</span>
            <span class="nt">BatchSize</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Batch size of each training step.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8</span>
            <span class="nt">ValBatchSize</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Batch size of each validation step.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8</span>
            <span class="nt">EarlyStop</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Terminate the training if the validation performance doesn&#39;t imrove after n epochs.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">6</span>
            <span class="nt">LossFunction</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Loss function for computing the objectives.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">smooth</span>
                <span class="nt">Choices</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;smooth&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;focal&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;bce&quot;</span><span class="p p-Indicator">]</span>
            <span class="nt">LabelType</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Determines the training target to be single- or multi-instrument scenario, and more options.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">note-stream</span>
                <span class="nt">Choices</span><span class="p">:</span> 
                    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">note-stream</span>
                    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">frame-stream</span>
                    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">note</span>
                    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">frame</span>
                    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">true-frame</span>
                    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">true-frame-stream</span>
                    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">pop-note-stream</span>
            <span class="nt">Channels</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Use different types of feature for training.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">List</span>
                <span class="nt">SubType</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">String</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;Spec&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;Ceps&quot;</span><span class="p p-Indicator">]</span>
                <span class="nt">Choices</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;Spec&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;GCoS&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;Ceps&quot;</span><span class="p p-Indicator">]</span>
            <span class="nt">Timesteps</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Length of time axis of the input feature.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
            <span class="nt">FeatureNum</span><span class="p">:</span>
                <span class="nt">Description</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">The target size of feature dimension.</span>
                <span class="nt">Type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Integer</span>
                <span class="nt">Value</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">352</span>
</pre></div>
</div>
</div>
</div>


          </div>
          <div class="page-nav">
            <div class="inner"><ul class="page-nav">
  <li class="prev">
    <a href="../patch-cnn/cli.html"
       title="previous chapter">← omnizart patch-cnn</a>
  </li>
  <li class="next">
    <a href="../drum/api.html"
       title="next chapter">Drum Transcription →</a>
  </li>
</ul><div class="footer" role="contentinfo">
      &#169; Copyright 2020, MCTLab.
    <br>
    Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.1 with <a href="https://github.com/schettino72/sphinx_press_theme">Press Theme</a>.
</div>
            </div>
          </div>
      </page>
    </div>
    
    
  </body>
</html>